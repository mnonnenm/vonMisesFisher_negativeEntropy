{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9c8b007",
   "metadata": {},
   "source": [
    "# Load news20 dataset\n",
    "\n",
    "MC toolkit: https://www.cs.utexas.edu/users/dml/software/mc/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f9b2cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.sparse\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from vMFne.utils_text import filter_features_against_stopwords, tfn\n",
    "\n",
    "only_train_data = True\n",
    "\n",
    "data_train = np.loadtxt('data/20news_preprocessed/train.data', dtype=int)\n",
    "data_train = scipy.sparse.coo_array((data_train[:,2], (data_train[:,0]-1, data_train[:,1]-1))).todense()\n",
    "\n",
    "if only_train_data:\n",
    "    data = data_train\n",
    "    labels = np.loadtxt('data/20news_preprocessed/train.label', dtype=int)\n",
    "else:\n",
    "    data_test = np.loadtxt('data/20news_preprocessed/test.data', dtype=int)\n",
    "    data_test = scipy.sparse.coo_array((data_test[:,2], (data_test[:,0]-1, data_test[:,1]-1))).todense()\n",
    "    data_train = np.concatenate([data_train, \n",
    "                                 np.zeros((data_train.shape[0], data_test.shape[1]-data_train.shape[1]),dtype=data_train.dtype)],\n",
    "                                axis=1)\n",
    "    data = np.concatenate([data_train, data_test], axis=0)\n",
    "    labels = np.concatenate([np.loadtxt('data/20news_preprocessed/train.label', dtype=int),\n",
    "                             np.loadtxt('data/20news_preprocessed/test.label', dtype=int)], axis=0)\n",
    "\n",
    "N, D_raw = data.shape\n",
    "\n",
    "dictionary = np.loadtxt('data/20news_preprocessed/vocabulary.txt', dtype=str)\n",
    "dictionary = dictionary[:D_raw] # training data alone does not contain whole dictionary actually\n",
    "\n",
    "data, dictionary = filter_features_against_stopwords(data, dictionary)\n",
    "labels = labels[data.sum(axis=1) > 0] # kick out that one document whose only occuring features \n",
    "data = data[data.sum(axis=1) > 0]     # are the stopwords 'more', 'say' and 'need' ...\n",
    "\n",
    "X = tfn(data, remove_dead_features=True, dtype=np.float32)\n",
    "N, D = X.shape\n",
    "\n",
    "plt.hist(np.mean(X==0., axis=1), density=True)\n",
    "plt.xlabel('sparisty of vectors')\n",
    "plt.ylabel('rel. frequency in dataset')\n",
    "plt.show()\n",
    "\n",
    "print('\\n')\n",
    "print('selecting D=' + str(D) + ' features out of ' + str(D_raw) + ' features in full dataset.')\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75710517",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Ψ0 = [None, 0.] # [None, 0.] means: compute correct Ψ(0), but don't numerically integrate Ψ'(μ), use approximation instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d51048",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# compute 'true' parameters using known labels\n",
    "from vMFne.negentropy import gradΨ\n",
    "from vMFne.bregman_clustering import posterior_marginal_vMF_mixture_Ψ\n",
    "from vMFne.moVMF import posterior_marginal_vMF_mixture_Φ\n",
    "\n",
    "ls = np.unique(labels)\n",
    "μs_true = np.stack([ np.mean(X[np.where(labels==ls[k])[0]],axis=0) for k in range(len(ls)) ], axis=0)\n",
    "w_true = np.array([ np.sum(labels==ls[k]) for k in range(len(ls))]) / len(labels)\n",
    "w_true = w_true / w_true.sum()\n",
    "print(w_true)\n",
    "μs_norm = np.linalg.norm(μs_true,axis=1) \n",
    "print(μs_true.dot(μs_true.T))\n",
    "print(μs_true.dot(μs_true.T) / np.outer(μs_norm,μs_norm))\n",
    "\n",
    "_, log_px_true_Ψ = posterior_marginal_vMF_mixture_Ψ(X,w_true,μs_true, Ψ0=Ψ0)\n",
    "LL_true_Ψ = log_px_true_Ψ.sum()\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Calculate the MI for the two clusterings\n",
    "def mi(class_true, class_est):\n",
    "    cont = metrics.cluster.contingency_matrix(class_true, class_est, sparse=True).astype(np.float64, copy=False)\n",
    "    mi = metrics.cluster.mutual_info_score(class_true, class_est, contingency=cont)\n",
    "    return mi\n",
    "\n",
    "class_true = sum([ (1.*i) * (labels==ls[i]) for i in range(len(ls))])\n",
    "ph_x_μ_true, _ = posterior_marginal_vMF_mixture_Ψ(X,w_true,μs_true, Ψ0=Ψ0)\n",
    "class_est_μ_true = np.argmax(ph_x_μ_true,axis=1)\n",
    "M_μ_true = confusion_matrix(class_true, class_est_μ_true)\n",
    "\n",
    "ηs_true = gradΨ(μs_true,D=D)\n",
    "_, log_px_true_Φ = posterior_marginal_vMF_mixture_Φ(X,w_true,ηs_true)\n",
    "LL_true_Φ = log_px_true_Φ.sum() # may differ from LL_true_Ψ by a constant offset\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(μs_true.T)\n",
    "plt.title('mean parameters per class')\n",
    "plt.xlabel('# of feature')\n",
    "plt.ylabel('μ[# of feature]')\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "\n",
    "plt.imshow(M_μ_true)\n",
    "plt.colorbar()\n",
    "plt.title('supervised model confusion matrix')\n",
    "plt.ylabel('MI='+str(mi(class_est_μ_true, class_true)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea4a4269",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from vMFne.bregman_clustering import posterior_marginal_vMF_mixture_Ψ\n",
    "from vMFne.bregman_clustering import softBregmanClustering_vMF\n",
    "\n",
    "K = 20\n",
    "μs, w, LL = softBregmanClustering_vMF(X, K=K, max_iter=50, Ψ0=Ψ0, verbose=True, μs_init=μs_true, w_init=w_true)\n",
    "\n",
    "ph_x, _ = posterior_marginal_vMF_mixture_Ψ(X,w,μs, Ψ0=Ψ0)\n",
    "class_est = np.argmax(ph_x,axis=1)\n",
    "M = confusion_matrix(class_true, class_est)\n",
    "plt.imshow(M)\n",
    "plt.ylabel('MI='+str(mi(class_est, class_true)))\n",
    "plt.colorbar()\n",
    "plt.title('learned model - LL= ' + str(LL[-1]))\n",
    "plt.show()\n",
    "\n",
    "LL_true = posterior_marginal_vMF_mixture_Ψ(X,w_true,μs_true, Ψ0=Ψ0)[1].sum()\n",
    "\n",
    "plt.plot(LL)\n",
    "plt.plot([0, len(LL)-1], [LL_true, LL_true], 'k--')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac55a96",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from vMFne.bregman_clustering import spherical_kmeans, softBregmanClustering_vMF\n",
    "from vMFne.bregman_clustering import posterior_marginal_vMF_mixture_Ψ\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import scipy\n",
    "\n",
    "all_μs, all_w, all_LL = [], [], []\n",
    "all_μs_kmean, all_w_kmean, all_c_kmean = [], [], []\n",
    "\n",
    "n_repets = 10\n",
    "for ii in range(n_repets):\n",
    "    _, w, c = spherical_kmeans(X, K=K, max_iter=100, verbose=False)\n",
    "    μs = np.stack([X[c==k].mean(axis=0) for k in range(K)],axis=0)\n",
    "    all_c_kmean.append(1 * c)\n",
    "    all_w_kmean.append(1. * w)\n",
    "    all_μs_kmean.append(1. * μs)\n",
    "    μs, w, LL = softBregmanClustering_vMF(X, K=K, max_iter=100, w_init=w, μs_init=μs, Ψ0=Ψ0, verbose=False)\n",
    "    all_μs.append(μs)\n",
    "    all_w.append(w)\n",
    "    all_LL.append(LL)\n",
    "    print(' - ' + str(ii+1) + '/' + str(n_repets))\n",
    "\n",
    "MIs = np.zeros(n_repets)\n",
    "for i in range(n_repets):\n",
    "    plt.figure(figsize=(12,6))\n",
    "    plt.subplot(1,2,1)\n",
    "    #class_est = all_c_kmean[i]\n",
    "    μs = all_μs_kmean[i]\n",
    "    w = all_w_kmean[i]\n",
    "    ph_x, _ = posterior_marginal_vMF_mixture_Ψ(X,w,μs, Ψ0=Ψ0)\n",
    "    class_est = np.argmax(ph_x,axis=1)\n",
    "    M = confusion_matrix(class_true, class_est)\n",
    "    _, idx_class_align = scipy.optimize.linear_sum_assignment(-M.T)\n",
    "    class_est_aligned = idx_class_align[class_est]\n",
    "    M = confusion_matrix(class_true, class_est_aligned)\n",
    "    plt.imshow(M)\n",
    "    plt.colorbar()\n",
    "    plt.title('learned model - sph. K-means')\n",
    "    MIs[i] = mi(class_true.flatten(), class_est.flatten())\n",
    "    plt.ylabel('MI=' + str(MIs[i]))\n",
    "\n",
    "    plt.subplot(1,2,2)\n",
    "    w = all_w[i]\n",
    "    μs = all_μs[i]\n",
    "    LL = all_LL[i]\n",
    "    ph_x, _ = posterior_marginal_vMF_mixture_Ψ(X,w,μs, Ψ0=Ψ0)\n",
    "    class_est = np.argmax(ph_x,axis=1)\n",
    "    M = confusion_matrix(class_true, class_est)\n",
    "    _, idx_class_align = scipy.optimize.linear_sum_assignment(-M.T)\n",
    "    class_est_aligned = idx_class_align[class_est]\n",
    "    M = confusion_matrix(class_true, class_est_aligned)\n",
    "    plt.imshow(M)\n",
    "    plt.colorbar()\n",
    "    plt.title('learned model - LL= ' + str(LL[-1]))\n",
    "    MIs[i] = mi(class_true.flatten(), class_est.flatten())\n",
    "    plt.ylabel('MI=' + str(MIs[i]))\n",
    "    plt.show()\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(np.stack(all_LL,axis=0).T)\n",
    "plt.plot([0, len(LL)], [LL_true_Ψ,LL_true_Ψ], 'k--')\n",
    "plt.xlabel('iteration')\n",
    "plt.ylabel('log-likelihood')\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(np.stack(all_LL,axis=0)[:,-1], MIs, 'o')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63b3aaa1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "n_repets = 7\n",
    "MIs = np.zeros(n_repets)\n",
    "for i in range(n_repets):\n",
    "    plt.figure(figsize=(12,6))\n",
    "    plt.subplot(1,2,1)\n",
    "    #class_est = all_c_kmean[i]\n",
    "    μs = all_μs_kmean[i]\n",
    "    w = all_w_kmean[i]\n",
    "    ph_x, px = posterior_marginal_vMF_mixture_Ψ(X,w,μs, Ψ0=Ψ0)\n",
    "    class_est = np.argmax(ph_x,axis=1)\n",
    "    M = confusion_matrix(class_true, class_est)\n",
    "    _, idx_class_align = scipy.optimize.linear_sum_assignment(-M.T)\n",
    "    class_est_aligned = idx_class_align[class_est]\n",
    "    M = confusion_matrix(class_true, class_est_aligned)\n",
    "    plt.imshow(M)\n",
    "    plt.colorbar()\n",
    "    plt.title('learned model - sph. K-means')\n",
    "    MIs[i] = mi(class_true.flatten(), class_est.flatten())\n",
    "    plt.ylabel('MI=' + str(MIs[i]))\n",
    "\n",
    "    plt.subplot(1,2,2)\n",
    "    w = all_w[i]\n",
    "    μs = all_μs[i]\n",
    "    LL = all_LL[i]\n",
    "    ph_x, px = posterior_marginal_vMF_mixture_Ψ(X,w,μs, Ψ0=Ψ0)\n",
    "    class_est = np.argmax(ph_x,axis=1)\n",
    "    M = confusion_matrix(class_true, class_est)\n",
    "    _, idx_class_align = scipy.optimize.linear_sum_assignment(-M.T)\n",
    "    class_est_aligned = idx_class_align[class_est]\n",
    "    M = confusion_matrix(class_true, class_est_aligned)\n",
    "    plt.imshow(M)\n",
    "    plt.colorbar()\n",
    "    plt.title('learned model - LL= ' + str(LL[-1]))\n",
    "    MIs[i] = mi(class_true.flatten(), class_est.flatten())\n",
    "    plt.ylabel('MI=' + str(MIs[i]))\n",
    "    plt.show()\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(np.stack(all_LL,axis=0).T)\n",
    "plt.plot([0, len(LL)], [LL_true_Ψ,LL_true_Ψ], 'k--')\n",
    "plt.xlabel('iteration')\n",
    "plt.ylabel('log-likelihood')\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(np.stack(all_LL,axis=0)[:,-1], MIs, 'o')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e532a077",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(n_repets):\n",
    "    ph_x, px = posterior_marginal_vMF_mixture_Ψ(X,all_w[i],all_μs[i], Ψ0=Ψ0)\n",
    "    plt.plot(np.sort(np.max(ph_x,axis=-1))[:200])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e4f5f9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from vMFne.bregman_clustering import softBregmanClustering_vMF, spherical_kmeans\n",
    "from vMFne.bregman_clustering import posterior_marginal_vMF_mixture_Ψ\n",
    "import scipy\n",
    "\n",
    "all_μs, all_w, all_LL = [], [], []\n",
    "\n",
    "n_repets = 3\n",
    "K = 20\n",
    "for ii in range(n_repets):\n",
    "    #_, w, c = spherical_kmeans(X=X, K=K, max_iter=20, verbose=False)\n",
    "    #μs = np.stack([X[c==k].mean(axis=0) for k in range(K)],axis=0)    \n",
    "    μs, w = None, None\n",
    "    μs, w, LL = softBregmanClustering_vMF(X, K=K, max_iter=50, Ψ0=Ψ0, verbose=True, μs_init=μs, w_init=w)\n",
    "    all_μs.append(μs)\n",
    "    all_w.append(w)\n",
    "    all_LL.append(LL)\n",
    "\n",
    "\n",
    "MIs = np.zeros(len(all_LL))\n",
    "i = 0\n",
    "for w,μs,LL in zip(all_w, all_μs, all_LL):\n",
    "    ph_x, px = posterior_marginal_vMF_mixture_Ψ(X,w,μs, Ψ0=Ψ0)\n",
    "    class_est = np.argmax(ph_x,axis=1)\n",
    "    M = confusion_matrix(class_true, class_est)\n",
    "    _, idx_class_align = scipy.optimize.linear_sum_assignment(-M.T)\n",
    "    class_est_aligned = idx_class_align[class_est]\n",
    "    M = confusion_matrix(class_true, class_est_aligned)    \n",
    "    plt.imshow(M)\n",
    "    plt.colorbar()\n",
    "    plt.title('learned model - LL= ' + str(LL[-1]))\n",
    "    MIs[i] = mi(class_true.flatten(), class_est.flatten()) \n",
    "    plt.ylabel('MI='+str(MIs[i]))\n",
    "    plt.show()\n",
    "    i += 1\n",
    "\n",
    "plt.plot(np.stack(all_LL,axis=0)[:,-1], MIs, 'o')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ae1535",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vMFne.bregman_clustering import softBregmanClustering_vMF, spherical_kmeans\n",
    "from vMFne.bregman_clustering import posterior_marginal_vMF_mixture_Ψ\n",
    "import scipy\n",
    "\n",
    "all_μs, all_w, all_LL = [], [], []\n",
    "\n",
    "n_repets = 3\n",
    "K = 20\n",
    "for ii in range(n_repets):\n",
    "    _, w, c = spherical_kmeans(X=X, K=K, max_iter=20, verbose=False)\n",
    "    μs = np.stack([X[c==k].mean(axis=0) for k in range(K)],axis=0)    \n",
    "    all_μs.append(μs)\n",
    "    all_w.append(w)\n",
    "    all_LL.append(np.ones(20))\n",
    "\n",
    "MIs = np.zeros(len(all_LL))\n",
    "i = 0\n",
    "for w,μs,LL in zip(all_w, all_μs, all_LL):\n",
    "    ph_x, px = posterior_marginal_vMF_mixture_Ψ(X,w,μs, Ψ0=Ψ0)\n",
    "    class_est = np.argmax(ph_x,axis=1)\n",
    "    M = confusion_matrix(class_true, class_est)\n",
    "    _, idx_class_align = scipy.optimize.linear_sum_assignment(-M.T)\n",
    "    class_est_aligned = idx_class_align[class_est]\n",
    "    M = confusion_matrix(class_true, class_est_aligned)    \n",
    "    plt.imshow(M)\n",
    "    plt.colorbar()\n",
    "    plt.title('learned model - LL= ' + str(LL[-1]))\n",
    "    MIs[i] = mi(class_true.flatten(), class_est.flatten()) \n",
    "    plt.ylabel('MI='+str(MIs[i]))\n",
    "    plt.show()\n",
    "    i += 1\n",
    "\n",
    "plt.plot(np.stack(all_LL,axis=0)[:,-1], MIs, 'o')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "550fd315",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d99016",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from vMFne.moVMF import moVMF, posterior_marginal_vMF_mixture_Φ\n",
    "\n",
    "ηs, w, LL = moVMF(X, K=3, max_iter=20, verbose=False, ηs_init = ηs_true, w_init = w_true)\n",
    "ph_x, px = posterior_marginal_vMF_mixture_Φ(X,w,ηs)\n",
    "\n",
    "plt.plot(LL)\n",
    "plt.plot([0, len(LL)], [LL_true_Φ,LL_true_Φ], 'k--')\n",
    "plt.xlabel('iteration')\n",
    "plt.ylabel('log-likelihood')\n",
    "plt.show()\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "class_est = np.argmax(ph_x,axis=1)\n",
    "M = confusion_matrix(class_true, class_est)\n",
    "plt.imshow(M)\n",
    "plt.colorbar()\n",
    "plt.title('learned model')\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(M_μ_true)\n",
    "plt.colorbar()\n",
    "plt.title('supervised model')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
