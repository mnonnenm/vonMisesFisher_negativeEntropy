{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9c8b007",
   "metadata": {},
   "source": [
    "# Load classic3 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a0a9f90",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pyreadr\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "# load dataset\n",
    "\n",
    "datasource = 'cclust_package'\n",
    "assert datasource in ['ZILGM', 'cclust_package']\n",
    "\n",
    "if datasource == 'ZILGM':\n",
    "    # retrieved from https://rdrr.io/github/bbeomjin/ZILGM/man/classic3.html\n",
    "    # N = 3890, D = 5896\n",
    "    classic3 = pyreadr.read_r('data/classic3.RData')['classic3']\n",
    "    X_raw = classic3.to_numpy()\n",
    "    labels = X_raw[:,-1]\n",
    "    X_raw = X_raw[:,1:-1].astype(dtype=np.float32)\n",
    "    word_lens = np.array([ len(classic3.keys()[1:-1][i]) for i in range(len(classic3.keys())-2) ])\n",
    "\n",
    "elif datasource == 'cclust_package':\n",
    "    # retrieved from https://github.com/franrole/cclust_package/blob/master/datasets/classic3.mat\n",
    "    # N = 3891, D = 4303 \n",
    "    import scipy.io\n",
    "\n",
    "    classic3 = scipy.io.loadmat('data/classic3.mat')\n",
    "    X_raw = classic3['A'].toarray()\n",
    "    labels = classic3['labels']\n",
    "    word_lens = np.array([ len(classic3['ms'][i,0][0]) for i in range(classic3['ms'].shape[0]) ])\n",
    "\n",
    "# remove 2-letter and 3-letter words \n",
    "idx = np.where(word_lens > 3)[0]\n",
    "X = X_raw[:,idx]    \n",
    "N, D_raw = X_raw.shape\n",
    "\n",
    "# remove dead features\n",
    "Nj = (X > 0).sum(axis=0) # number of documents containing word j = 1, ..., D\n",
    "idx = np.where(Nj > 0)[0]\n",
    "sub_sample_features = False\n",
    "if sub_sample_features:\n",
    "    D_max = 200\n",
    "    D = np.min((D,D_max))\n",
    "    idx__ = np.argsort(Nj)\n",
    "    idx = idx__[-D:]\n",
    "D = len(idx)\n",
    "X, Nj = X[:,idx], Nj[idx]\n",
    "\n",
    "# tfn scheme - normalized term frequency-inverse document frequency\n",
    "gj = np.log(N/Nj)\n",
    "si = 1. / np.sqrt(((X * gj.reshape(1,D))**2).sum(axis=1))\n",
    "\n",
    "X = X * np.outer(si, gj)\n",
    "\n",
    "plt.hist(np.mean(X_raw==0., axis=1), density=True)\n",
    "plt.xlabel('sparisty of vectors')\n",
    "plt.ylabel('rel. frequency in dataset')\n",
    "plt.show()\n",
    "\n",
    "print('\\n')\n",
    "print('selecting D=' + str(D) + ' features out of ' + str(D_raw) + ' features in full dataset.')\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75710517",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Ψ0 = [0., 1e-4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d51048",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# compute 'true' parameters using known labels\n",
    "from vMFne.negentropy import gradΨ\n",
    "from vMFne.bregman_clustering import posterior_marginal_vMF_mixture_Ψ\n",
    "from vMFne.moVMF import posterior_marginal_vMF_mixture_Φ\n",
    "\n",
    "ls = np.unique(labels)\n",
    "μs_true = np.stack([ np.mean(X[np.where(labels==ls[k])[0]],axis=0) for k in range(len(ls)) ], axis=0)\n",
    "w_true = np.array([ np.sum(labels==ls[k]) for k in range(len(ls))]) / len(labels)\n",
    "w_true = w_true / w_true.sum()\n",
    "print(w_true)\n",
    "μs_norm = np.linalg.norm(μs_true,axis=1) \n",
    "print(μs_true.dot(μs_true.T))\n",
    "print(μs_true.dot(μs_true.T) / np.outer(μs_norm,μs_norm))\n",
    "\n",
    "_, px_true_Ψ = posterior_marginal_vMF_mixture_Ψ(X,w_true,μs_true, Ψ0=Ψ0)\n",
    "LL_true_Ψ = np.log(px_true_Ψ).sum()\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "class_true = sum([ (1.*i) * (labels==ls[i]) for i in range(len(ls))])\n",
    "ph_x_μ_true, _ = posterior_marginal_vMF_mixture_Ψ(X,w_true,μs_true, Ψ0=Ψ0)\n",
    "class_est_μ_true = np.argmax(ph_x_μ_true,axis=1)\n",
    "M_μ_true = confusion_matrix(class_true, class_est_μ_true)\n",
    "\n",
    "ηs_true = gradΨ(μs_true,D=D)\n",
    "_, px_true_Φ = posterior_marginal_vMF_mixture_Φ(X,w_true,ηs_true)\n",
    "LL_true_Φ = np.log(px_true_Φ).sum() # may differ from LL_true_Ψ by a constant offset\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(μs_true.T)\n",
    "plt.title('mean parameters per class')\n",
    "plt.xlabel('# of feature')\n",
    "plt.ylabel('μ[# of feature]')\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "\n",
    "plt.imshow(M_μ_true)\n",
    "plt.colorbar()\n",
    "plt.title('supervised model confusion matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e4f5f9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from vMFne.bregman_clustering import softBregmanClustering_vMF\n",
    "from vMFne.bregman_clustering import posterior_marginal_vMF_mixture_Ψ\n",
    "\n",
    "all_μs, all_w, all_LL = [], [], []\n",
    "\n",
    "n_repets = 10\n",
    "for ii in range(n_repets):\n",
    "    μs, w, LL = softBregmanClustering_vMF(X, K=3, max_iter=25, Ψ0=Ψ0, verbose=True)#, μs_init = μs_true, w_init = w_true)\n",
    "    all_μs.append(μs)\n",
    "    all_w.append(w)\n",
    "    all_LL.append(LL)\n",
    "\n",
    "plt.plot(LL)\n",
    "plt.plot([0, len(LL)], [LL_true_Ψ,LL_true_Ψ], 'k--')\n",
    "plt.xlabel('iteration')\n",
    "plt.ylabel('log-likelihood')\n",
    "plt.show()\n",
    "\n",
    "ph_x, px = posterior_marginal_vMF_mixture_Ψ(X,w,μs, Ψ0=Ψ0)\n",
    "\n",
    "print('w', w)\n",
    "print(μs.dot(μs.T))\n",
    "norm_μs = np.linalg.norm(μs, axis=1)\n",
    "print(μs.dot(μs.T) / np.outer(norm_μs,norm_μs))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "class_est = np.argmax(ph_x,axis=1)\n",
    "M = confusion_matrix(class_true, class_est)\n",
    "plt.imshow(M)\n",
    "plt.colorbar()\n",
    "plt.title('learned model')\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(M_μ_true)\n",
    "plt.colorbar()\n",
    "plt.title('supervised model')\n",
    "\n",
    "print('M', M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57445253",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for w,μs,LL in zip(all_w, all_μs, all_LL):\n",
    "    ph_x, px = posterior_marginal_vMF_mixture_Ψ(X,w,μs, Ψ0=Ψ0)\n",
    "    class_est = np.argmax(ph_x,axis=1)\n",
    "    M = confusion_matrix(class_true, class_est)\n",
    "    plt.imshow(M)\n",
    "    plt.colorbar()\n",
    "    plt.title('learned model - LL= ' + str(LL[-1]))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42dfa950",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "581355ce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot(np.stack(all_LL,axis=0).T)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c49d17c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec8a288d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "confusion_matrix?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "550fd315",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d99016",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from vMFne.moVMF import moVMF, posterior_marginal_vMF_mixture_Φ\n",
    "\n",
    "ηs, w, LL = moVMF(X, K=3, max_iter=20, verbose=False, ηs_init = ηs_true, w_init = w_true)\n",
    "ph_x, px = posterior_marginal_vMF_mixture_Φ(X,w,ηs)\n",
    "\n",
    "plt.plot(LL)\n",
    "plt.plot([0, len(LL)], [LL_true_Φ,LL_true_Φ], 'k--')\n",
    "plt.xlabel('iteration')\n",
    "plt.ylabel('log-likelihood')\n",
    "plt.show()\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "class_est = np.argmax(ph_x,axis=1)\n",
    "M = confusion_matrix(class_true, class_est)\n",
    "plt.imshow(M)\n",
    "plt.colorbar()\n",
    "plt.title('learned model')\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(M_μ_true)\n",
    "plt.colorbar()\n",
    "plt.title('supervised model')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
